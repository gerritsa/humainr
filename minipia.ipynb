{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example copy:\n",
    "\n",
    "1 Torchaudio load from S3:\n",
    "client = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "response = client.get_object(Bucket=S3_BUCKET, Key=S3_KEY)\n",
    "waveform, sample_rate = torchaudio.load(response['Body'])\n",
    "plot_specgram(waveform, sample_rate, title=\"From S3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre installatie\n",
    "- sudo apt install libsndfile1-dev\n",
    "- sudo apt install awscli\n",
    "\n",
    "- aws configure sso (Met informatie geleverd door Nick)\n",
    "\n",
    "- conda create --name humainr python=3.9\n",
    "- pip install boto3\n",
    "- pip install transformers\"[speech, sentencepiece]\"\n",
    "- pip install datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verschillende imports voor het programma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### General\n",
    "import os\n",
    "import torch\n",
    "import uuid\n",
    "import shutil\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "### s3 and DynamoDB\n",
    "import boto3\n",
    "\n",
    "### Transcibing trough ML\n",
    "import torchaudio\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset, Audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuratie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_voice_en_38497561 (copy).mp3\n",
      "common_voice_en_38497561.mp3\n",
      "test.json\n",
      "humainr-aws-intro-bucket\n",
      "common_voice_en_38497561.mp3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "boto3.setup_default_session(profile_name='AWSIntroTraining-408122842185')\n",
    "s3 = boto3.resource('s3')\n",
    "bucketname = 'humainr-aws-intro-bucket'\n",
    "bucket = s3.Bucket(bucketname)\n",
    "\n",
    "sync_path = 'data/new/'\n",
    "arch_path = 'data/archive/'\n",
    "test_file = 'common_voice_en_38497561.mp3'\n",
    "\n",
    "for my_bucket_object in bucket.objects.all():\n",
    "    print(my_bucket_object.key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwerk de klaarstaande audiobestanden naar de AWS bucket\n",
    "\n",
    "1 - Upload file naar S3\n",
    "2 - Verplaats bestand van de sync_dir naar de arch_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inhoud van de locale disk:\n",
      "validation.txt\n",
      "\n",
      "Inhoud van de s3 bucket:\n",
      "common_voice_en_38497561 (copy).mp3\n",
      "common_voice_en_38497561.mp3\n",
      "test.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Inhoud van de locale disk:\")\n",
    "for entry in os.listdir(sync_path):\n",
    "    print(entry)\n",
    "    if entry.endswith('.mp3'):\n",
    "        bucket.upload_file(sync_path + entry, entry)\n",
    "        shutil.move(sync_path + entry, arch_path + entry)\n",
    "print(\"\")\n",
    "\n",
    "print(\"Inhoud van de s3 bucket:\")\n",
    "for my_bucket_object in bucket.objects.all():\n",
    "    print(my_bucket_object.key)\n",
    "    ### Volgende regel is voor debug om de s3 bucket geheel leeg te gooien.\n",
    "    #my_bucket_object.delete()\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sectie voor de transcriptie:\n",
    "\n",
    "1 - Zet bytestream om naar bruikbare data\n",
    "2 - Pas de samplingrate aan\n",
    "3 - Extraheer feautures\n",
    "4 - Transcribeer de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Speech2TextForConditionalGeneration were not initialized from the model checkpoint at facebook/s2t-small-librispeech-asr and are newly initialized: ['model.encoder.embed_positions.weights', 'model.decoder.embed_positions.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6299e-12,  9.4797e-12, -1.5897e-12,  ..., -3.0086e-04,\n",
      "         -1.3465e-04, -3.2022e-05]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "### Laad de file/files in de dataset die transcribed moet worden\n",
    "#ds = load_dataset(\"audiofolder\", data_files=[sync_path + test_file], split=\"train\")\n",
    "obj = s3.Object(bucket_name=bucketname, key=test_file)\n",
    "response = obj.get()\n",
    "audio_bytes = BytesIO(response['Body'].read())\n",
    "\n",
    "### Zet de bytestream van de s3 opslag om naar een numberarray\n",
    "waveform, sample_rate = torchaudio.load(audio_bytes, format=\"mp3\")\n",
    "\n",
    "### Zet de sampling rate om naar 16000 voor het getrainde model\n",
    "waveform = torchaudio.functional.resample(waveform, orig_freq=sample_rate, new_freq=16000)\n",
    "print(waveform)\n",
    "\n",
    "### Genereer features uit de data\n",
    "inputs = processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "### [TODO] Uitzoeken wat deze functie precies doet.\n",
    "generated_ids = model.generate(inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"])\n",
    "\n",
    "### [TODO] Omzetten prediction naar transcriptie.\n",
    "transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opslaan transcriptie\n",
    "1 - Tijdelijk json bestand\n",
    "2 - Upload naar de s3 bucket\n",
    "3 - Verwijder tijdelijk bestand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_voice_en_38497561 (copy).mp3\n",
      "common_voice_en_38497561.mp3\n",
      "test.json\n",
      "9885e413-f37e-4131-bb7d-a666d2742ff7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"test.json\", \"w\") as file:\n",
    "    json.dump(transcription, file)\n",
    "\n",
    "bucket.upload_file('test.json', 'test.json')\n",
    "\n",
    "os.remove('test.json')\n",
    "\n",
    "for my_bucket_object in bucket.objects.all():\n",
    "    print(my_bucket_object.key)\n",
    "\n",
    "print(uuid.uuid4())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwerk de transcriptie en metadata in DynamoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwerk de al verwerkte data naar een leesbare html pagina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start html server op om verwerkte data te publiseren\n",
    "\n",
    "[TODO] Pagina maken om data te uploaden en te gaan verwerken. (als er tijd over is)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
